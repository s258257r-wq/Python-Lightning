import torch
from torch import nn, Tensor
from torch.nn import functional as F
import pytorch_lightning as pl
from torchmetrics.classification import Accuracy

class MNISTLightningModel(pl.LightningModule):
    """
    MNIST手書き文字認識のためのLightningModule。
    """
    def __init__(self, hidden_size: int = 64, lr: float = 2e-4) -> None:
        super().__init__()
        self.save_hyperparameters() # 引数を self.hparams に自動保存
        
        self.layer_1 = nn.Linear(28 * 28, hidden_size)
        self.layer_2 = nn.Linear(hidden_size, hidden_size)
        self.layer_3 = nn.Linear(hidden_size, 10)
        
        # 指標の定義（型ヒント: Accuracy）
        self.accuracy = Accuracy(task="multiclass", num_classes=10)

    def forward(self, x: Tensor) -> Tensor:
        # 入力の変形: (batch, 1, 28, 28) -> (batch, 784)
        batch_size, channels, width, height = x.size()
        x = x.view(batch_size, -1)
        
        x = F.relu(self.layer_1(x))
        x = F.relu(self.layer_2(x))
        x = self.layer_3(x)
        return x

    def training_step(self, batch: tuple[Tensor, Tensor], batch_idx: int) -> Tensor:
        x, y = batch
        logits = self(x)
        loss = F.cross_entropy(logits, y)
        
        # ログ出力
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def validation_step(self, batch: tuple[Tensor, Tensor], batch_idx: int) -> None:
        x, y = batch
        logits = self(x)
        acc = self.accuracy(logits, y)
        self.log("val_acc", acc, prog_bar=True)

    def configure_optimizers(self) -> torch.optim.Optimizer:
        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)
